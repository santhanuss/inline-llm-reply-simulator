# No external Python deps
# Uses subprocess to call llama.cpp
